{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grain Size Distribution - Height Correlation Function\n",
    "\n",
    "Find relevant parameters describing the topography of sputtered Ruthenium thin films on Si substrate\n",
    "How:\n",
    "- Roughness RMS\n",
    "- Fit exponential increase\n",
    "- Take intersection between RMS asymptote and Fit\n",
    "\n",
    "Output parameters:\n",
    "- Roughness\n",
    "- Correlation Length\n",
    "- Alpha exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib nbagg\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm\n",
    "from skimage import data, img_as_float, filters\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import cv2\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True #or 'False' when you do not want to debug\n",
    "\n",
    "path = \"/Users/sfiligoj/Desktop/Ruthenium under heat chapter/SSP_AFM_all\"\n",
    "os.chdir(path)\n",
    "filess = os.listdir()\n",
    "# filess = [f for f in filess if f.endswith('txt')]\n",
    "# filess = ['Ru_LH_asdep_500nm_FLAT.008.txt','Ru_H_asdep_500nm_FLAT.004.txt','Ru_L_asdep_500nm_FLAT.005.txt']\n",
    "filess = ['Ru_H_asdep_1um_FLAT_102.txt','Ru_H_asdep_FLAT.003.txt','Ru_LH_asdep_FLAT.009.txt','Ru_L_asdep_FLAT.006.txt']\n",
    "# filess = ['Ru_L_250C_FLAT.008.txt','Ru_H_250C_FLAT.016.txt','Ru_LH_250C_FLAT.013.txt','Ru_LH_250C_FLAT.012.txt']\n",
    "\n",
    "# 'Ru_H_asdep_1um_FLAT_102.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dictionary of Scan Size values:\n",
    "with open('ScanSizes.json', 'r') as f:\n",
    "    ScanSize_dict = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     5,
     11,
     17,
     77,
     80
    ]
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "data = dict.fromkeys(filess)\n",
    "for i,file in enumerate(filess[:]):\n",
    "    \n",
    "    if '*' in file:\n",
    "        continue   \n",
    "    if '_H_' in file:\n",
    "        density = 'High'\n",
    "        if 'asdep' in file:\n",
    "            temperature = 'as-deposited'\n",
    "        else:\n",
    "            temperature = temperature = file[5:9]        \n",
    "    if '_L_' in file:\n",
    "        density = 'Low'\n",
    "        if 'asdep' in file:\n",
    "            temperature = 'as-deposited'\n",
    "        else:\n",
    "            temperature = temperature = file[5:9]          \n",
    "    if '_LH_' in file:\n",
    "        density = 'Low-High'\n",
    "        if 'asdep' in file:\n",
    "            temperature = 'as-deposited'\n",
    "        else:\n",
    "            temperature = temperature = file[6:10]\n",
    "            \n",
    "    data[file] = {}\n",
    "    \n",
    "    filesize = os.path.getsize(file)     #to differentiate between 512x512 px or 1024x1024 px img\n",
    "    Pix_width = int(np.sqrt(filesize/32))\n",
    "    Pix_height = Pix_width\n",
    " \n",
    "    data[file]['img'] = np.genfromtxt(file, skip_header=1).reshape((Pix_width,Pix_height))\n",
    "    \n",
    "    if Pix_width == 1024:\n",
    "        print(f\"Resampling file: {file}\")\n",
    "        data[file]['orig'] = data[file]['img']\n",
    "        # overwrites the original data with the downsampled one\n",
    "        # use cv2.INTER_LINEAR because it matches the histogram best\n",
    "        data[file]['img'] = cv2.resize(data[file]['img'], dsize=(512,512),interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    N_Pixel = data[file]['img'].shape[1] \n",
    "    ScanSize = 1000                       # nm\n",
    "    StepSize = ScanSize/N_Pixel                         # nm/px   \n",
    "    Xdelta = np.linspace(StepSize, ScanSize, num=N_Pixel)\n",
    "\n",
    "    rows, cols = data[file]['img'].shape\n",
    "    midrows = rows // 2\n",
    "    midcols = cols // 2\n",
    "    \n",
    "    quadrant1 = data[file]['img'][: midrows ,: midcols ]\n",
    "    quadrant2 = data[file]['img'][: midrows , midcols :]\n",
    "    quadrant3 = data[file]['img'][ midrows :,: midcols ]\n",
    "    quadrant4 = data[file]['img'][ midrows :, midcols :]\n",
    "    \n",
    "    quadrants = [quadrant1, quadrant2, quadrant3, quadrant4]\n",
    "    \n",
    "    for j,quad in enumerate(quadrants):\n",
    "        \n",
    "        print(f'running file:{file}, quadrant {j}')\n",
    "        \n",
    "        # ***    Calculate theoretical asymptotic value of the Height difference correlation: 2w^2   ***\n",
    "    \n",
    "        HeightSq = (quad)**2                        \n",
    "        if False: print(f'HeightSq shape = {HeightSq.shape}') #  (should be 512x512)\n",
    "        RMS_sq = np.mean(HeightSq)               #   RMS^2 = w^2 - also called Interface Width\n",
    "        if False: print(f'RMS squared = {RMS_sq}')            #  (should be a scalar)\n",
    "        RMS = np.sqrt(RMS_sq)\n",
    "\n",
    "\n",
    "        #error on the measurements:\n",
    "    #     error_sq = np.sort(sum((np.sqrt(HeightSq) - RMS)**2)/(len(HeightSq)-1))\n",
    "\n",
    "        # ***    Calculate Height-Height correlation function:   ***\n",
    "\n",
    "        HHcorr = np.zeros(N_Pixel, dtype='float')\n",
    "        autocorr = np.zeros(N_Pixel, dtype='float')\n",
    "\n",
    "        for px_dist in range(0, N_Pixel):\n",
    "            shifted_data = quad[:,px_dist+1:].astype(float)\n",
    "            data_section = quad[:,:-px_dist-1].astype(float)\n",
    "            if False:\n",
    "                print(f'shifted data= {shifted_data.shape}')\n",
    "                print(f'sectioned data= {data_section.shape}')\n",
    "            difference = (data_section-shifted_data)**2\n",
    "            product = (data_section*shifted_data)\n",
    "            HHcorr[px_dist] = np.mean(difference)\n",
    "            autocorr[px_dist]= 2*np.mean(product)\n",
    "\n",
    "        # ***    Fit the data:   ***\n",
    "\n",
    "        # consider the following number of pixels for the fit:\n",
    "    #   CutoffPointPLaw = int(np.argwhere(HHcorr>=2*RMS_sq)[0])\n",
    "        CutoffPointPLaw = int(np.argwhere(Xdelta>=10)[0])\n",
    "\n",
    "\n",
    "        a0=0\n",
    "        # weights for the fit, used for Method 1\n",
    "        y_err1 = 1/(np.arange(1,CutoffPointPLaw+1))**2\n",
    "        # For this Method, we define:\n",
    "        y_err2 = np.sqrt(HHcorr[:CutoffPointPLaw])\n",
    "        y_err3 = np.arange(a0,CutoffPointPLaw+a0)**2\n",
    "        weights = np.exp(y_err3)\n",
    "\n",
    "\n",
    "        # ***    Model for describing power law (on log scale):\n",
    "\n",
    "        Model = lambda x, a, alpha: a*x**(2*alpha)\n",
    "\n",
    "\n",
    "        # ***    Fit data using Model\n",
    "\n",
    "        popt, pcov = curve_fit(Model, Xdelta[a0:CutoffPointPLaw+a0], HHcorr[a0:CutoffPointPLaw+a0], \n",
    "                               sigma = weights)\n",
    "\n",
    "\n",
    "        # ***    Extracting the correlation length   ***\n",
    "\n",
    "        #*popt= a,alpha\n",
    "        a = popt[0]                                         # primo parametro dipendente\n",
    "        alpha = popt[1]                                     # secondo paramtero dipendente\n",
    "\n",
    "        # Equating a*(x**alpha)= 2*RMS_sq you extract x, the correlation length\n",
    "        CorrLength= (1/a *(2*RMS_sq))**(1/(2*alpha))\n",
    "\n",
    "        \n",
    "        label = f\"{file[:-4]}_Q{j}\"\n",
    "        # ***    Plot and save results:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x = Xdelta, \n",
    "                y = HHcorr,\n",
    "                mode = 'lines',\n",
    "                name = label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(ncols=2) #, sharex=True, sharey=True)\n",
    "# ax[0].imshow(data[file]['img'])\n",
    "# ax[1].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots() #, sharex=True, sharey=True)\n",
    "\n",
    "# matched = np.hstack((img, img, img, img)) # to match the total number of pixels from the resized image and the orig\n",
    "# ax.hist(matched.ravel(), bins=75, alpha = 0.4)\n",
    "# ax.hist(data[file]['img'].ravel(), bins = 75, alpha = 0.4)\n",
    "# fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig.update_layout(title=\"HHcorr\",\n",
    "                  xaxis_type=\"log\", \n",
    "                  yaxis_type=\"log\",\n",
    "                 )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     4,
     10,
     16
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotting = True\n",
    "for i,file in enumerate(filess[:1]):\n",
    "    \n",
    "    if '*' in file:\n",
    "        continue   \n",
    "    if '_H_' in file:\n",
    "        density = 'High'\n",
    "        if 'asdep' in file:\n",
    "            temperature = 'as-deposited'\n",
    "        else:\n",
    "            temperature = temperature = file[5:9]        \n",
    "    if '_L_' in file:\n",
    "        density = 'Low'\n",
    "        if 'asdep' in file:\n",
    "            temperature = 'as-deposited'\n",
    "        else:\n",
    "            temperature = temperature = file[5:9]          \n",
    "    if '_LH_' in file:\n",
    "        density = 'Low-High'\n",
    "        if 'asdep' in file:\n",
    "            temperature = 'as-deposited'\n",
    "        else:\n",
    "            temperature = temperature = file[6:10]\n",
    "                 \n",
    "    rows, cols = data[file]['img'].shape\n",
    "    midrows = rows // 2\n",
    "    midcols = cols // 2\n",
    "    \n",
    "    quadrant1 = data[file]['img'][:midrows ,:midcols]\n",
    "    quadrant2 = data[file]['img'][:midrows , midcols:]\n",
    "    quadrant3 = data[file]['img'][ midrows:,:midcols]\n",
    "    quadrant4 = data[file]['img'][ midrows:, midcols:]\n",
    "    \n",
    "    quadrants = [quadrant1, quadrant2, quadrant3, quadrant4]\n",
    "    \n",
    "    for j,quad in enumerate(quadrants):\n",
    "        \n",
    "        print(f'running file:{file}, quadrant {j}')\n",
    "        \n",
    "        # ***    Calculate theoretical asymptotic value of the Height difference correlation: 2w^2   ***\n",
    "\n",
    "        N_Pixel = quad.shape[1] \n",
    "        print(N_Pixel)\n",
    "        ScanSize = 500                       # nm\n",
    "        StepSize = ScanSize/N_Pixel                         # nm/px   \n",
    "#         Xdelta = np.arange(N_Pixel)*StepSize               # Switching from pixels to step size in nm\n",
    "\n",
    "        Xdelta = np.linspace(StepSize, ScanSize, num=N_Pixel)\n",
    "        # Should be close to 0 when you have flattened out the image, so it is omittable\n",
    "        AvgHeight = np.mean(quad)                            \n",
    "        if False: print(f'AvgHeight = {AvgHeight}')        \n",
    "        HeightSq = (quad-AvgHeight)**2                        \n",
    "        if False: print(f'HeightSq shape = {HeightSq.shape}') #  (should be 512x512)\n",
    "        RMS_sq = np.mean(HeightSq)               #   RMS^2 = w^2 - also called Interface Width\n",
    "        if False: print(f'RMS squared = {RMS_sq}')            #  (should be a scalar)\n",
    "        RMS = np.sqrt(RMS_sq)\n",
    "\n",
    "\n",
    "        #error on the measurements:\n",
    "    #     error_sq = np.sort(sum((np.sqrt(HeightSq) - RMS)**2)/(len(HeightSq)-1))\n",
    "\n",
    "        # ***    Calculate Height-Height correlation function:   ***\n",
    "\n",
    "        HHcorr = np.zeros(N_Pixel, dtype='float')\n",
    "        autocorr = np.zeros(N_Pixel, dtype='float')\n",
    "\n",
    "        for px_dist in range(0, N_Pixel):\n",
    "            shifted_data = quad[:,px_dist+1:].astype(float)\n",
    "            data_section = quad[:,:-px_dist-1].astype(float)\n",
    "            if False:\n",
    "                print(f'shifted data= {shifted_data.shape}')\n",
    "                print(f'sectioned data= {data_section.shape}')\n",
    "            difference = (data_section-shifted_data)**2\n",
    "            product = (data_section*shifted_data)\n",
    "            HHcorr[px_dist] = np.mean(difference)\n",
    "            autocorr[px_dist]= 2*np.mean(product)\n",
    "\n",
    "        # ***    Fit the data:   ***\n",
    "\n",
    "        # consider the following number of pixels for the fit:\n",
    "    #     CutoffPointPLaw = int(np.argwhere(HHcorr>=2*RMS_sq)[0])\n",
    "        CutoffPointPLaw = int(np.argwhere(Xdelta>=10)[0])\n",
    "\n",
    "\n",
    "        a0=0\n",
    "        # weights for the fit, used for Method 1\n",
    "        y_err1 = 1/(np.arange(1,CutoffPointPLaw+1))**2\n",
    "        # For this Method, we define:\n",
    "        y_err2 = np.sqrt(HHcorr[:CutoffPointPLaw])\n",
    "        y_err3 = np.arange(a0,CutoffPointPLaw+a0)**2\n",
    "        weights = np.exp(y_err3)\n",
    "\n",
    "\n",
    "        # ***    Model for describing power law (on log scale):\n",
    "\n",
    "        Model = lambda x, a, alpha: a*x**(2*alpha)\n",
    "\n",
    "\n",
    "        # ***    Fit data using Model\n",
    "\n",
    "        popt, pcov = curve_fit(Model, Xdelta[a0:CutoffPointPLaw+a0], HHcorr[a0:CutoffPointPLaw+a0], \n",
    "                               sigma = weights)\n",
    "\n",
    "\n",
    "        # ***    Extracting the correlation length   ***\n",
    "\n",
    "        #*popt= a,alpha\n",
    "        a = popt[0]                                         # primo parametro dipendente\n",
    "        alpha = popt[1]                                     # secondo paramtero dipendente\n",
    "\n",
    "        # Equating a*(x**alpha)= 2*RMS_sq you extract x, the correlation length\n",
    "        CorrLength= (1/a *(2*RMS_sq))**(1/(2*alpha))\n",
    "        \n",
    "        #For all the beautiful colors go to   http://colorbrewer2.org/#type=qualitative&scheme=Paired&n=4\n",
    "        #                                   &  https://www.quackit.com/css/css_color_codes.cfm\n",
    "\n",
    "        # For axis settings:                 https://matplotlib.org/3.1.0/api/axes_api.html#axis-scales\n",
    "\n",
    "        if plotting:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (9,5))\n",
    "            ax = np.ravel(ax)\n",
    "\n",
    "            AFM = ax[0].imshow(quad, cmap = 'inferno', vmax=1.8)\n",
    "            ax[0].axis('off')\n",
    "            ax[0].set_title(f\"AFM Image\")\n",
    "        #     fig.colorbar(AFM, ax=ax[0])\n",
    "\n",
    "            ax[1].loglog(Xdelta, HHcorr, label = 'HH corr', linewidth = 2, alpha=1)\n",
    "                    #and its errors:\n",
    "                    #plt.errorbar(Xdelta, HHcorr, yerr=e, fmt=\".\")\n",
    "\n",
    "            # plot the fit\n",
    "            ax[1].loglog(Xdelta[:CutoffPointPLaw], \n",
    "                         Model(Xdelta[:CutoffPointPLaw],*popt), \n",
    "                         label = 'Fit', \n",
    "                         linewidth = 1, \n",
    "                         linestyle='dashed', \n",
    "                         alpha = 0.8, color ='k')\n",
    "\n",
    "            # show correlation length \n",
    "            ax[1].scatter(CorrLength, 2*RMS_sq, marker='o', color='orange')\n",
    "            ax[1].vlines(CorrLength,HHcorr[0],2*RMS_sq, linestyle=\"dotted\", linewidth=1)\n",
    "            ax[1].hlines(2*RMS_sq, Xdelta[0], Xdelta[N_Pixel-2], linestyle=\"dashed\",linewidth=1)\n",
    "\n",
    "            # plt.legend()\n",
    "            ax[1].tick_params(direction='in', length=3, width=0.5, colors='k')\n",
    "            ax[1].set(xticks=(1,10,CorrLength,100, ScanSize))\n",
    "            ax[1].set(xticklabels=(0,10,'$\\\\xi $',100,ScanSize))\n",
    "            ax[1].set(yticks=(1,2*RMS_sq))\n",
    "            ax[1].set_yticklabels(('','$2w^2$'))\n",
    "            ax[1].tick_params(axis='x', which='minor', direction ='in', bottom=True)\n",
    "            ax[1].tick_params(axis='y', which='minor', direction ='in',labelleft=False)\n",
    "\n",
    "\n",
    "            ax[1].set(ylabel='Roughness, RMS [nm$^2$]')\n",
    "            ax[1].set(xlabel='Scan size, L [nm]')\n",
    "            ax[1].set_title(f\"Height Correlation Function\")\n",
    "\n",
    "            ax[1].set_xlim(Xdelta[0], ScanSize)\n",
    "            ax[1].set_ylim(HHcorr[0], 1.2*max(HHcorr))\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            sup_title = f\"File{file[-7:-4]}: HH-function for {temperature} {density} density Ru - $\\\\xi $ = {CorrLength:.4} nm\"\n",
    "            fig.suptitle(sup_title, fontsize=14)\n",
    "            fig.subplots_adjust(top=0.83)\n",
    "\n",
    "            figname = f\"{sup_title}.png\"\n",
    "        #     fig.savefig(f'HH function for {temperature} {density} density Ru - {file[-7:-4]}.png', dpi=600)\n",
    "            #plt.savefig('High density HH function - all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(filess[:]):\n",
    "\n",
    "    rows, cols = data[file]['img'].shape\n",
    "    midrows = rows // 2\n",
    "    midcols = cols // 2\n",
    "    quadrant1 = data[file]['img'][:midrows ,:midcols]\n",
    "    quadrant2 = data[file]['img'][:midrows , midcols:]\n",
    "    quadrant3 = data[file]['img'][ midrows:,:midcols]\n",
    "    quadrant4 = data[file]['img'][ midrows:, midcols:]\n",
    "    \n",
    "    quadrants = [quadrant1, quadrant2, quadrant3, quadrant4]\n",
    "    \n",
    "    for j,quad in enumerate(quadrants):\n",
    "        \n",
    "        print(f'running file:{file}, quadrant {j}')\n",
    "        \n",
    "        # ***    Calculate theoretical asymptotic value of the Height difference correlation: 2w^2   ***\n",
    "\n",
    "        ScanSize = 250                       # nm\n",
    "        N_Pixel = quad.shape[1] \n",
    "        Xdelta = np.linspace(StepSize, ScanSize, num=N_Pixel)\n",
    "\n",
    "        AvgHeight = np.mean(quad)                            # Should be close to 0 when you have flattened out the image, so it is omittable\n",
    "        if False: print(f'AvgHeight = {AvgHeight}')        \n",
    "        HeightSq = (quad-AvgHeight)**2                        \n",
    "        if False: print(f'HeightSq shape = {HeightSq.shape}') #  (should be 512x512)\n",
    "        RMS_sq = np.mean(HeightSq)               #   RMS^2 = w^2 - also called Interface Width\n",
    "        if False: print(f'RMS squared = {RMS_sq}')            #  (should be a scalar)\n",
    "        RMS = np.sqrt(RMS_sq)\n",
    "\n",
    "\n",
    "        #error on the measurements:\n",
    "    #     error_sq = np.sort(sum((np.sqrt(HeightSq) - RMS)**2)/(len(HeightSq)-1))\n",
    "\n",
    "        # ***    Calculate Height-Height correlation function:   ***\n",
    "\n",
    "        HHcorr = np.zeros(N_Pixel, dtype='float')\n",
    "        autocorr = np.zeros(N_Pixel, dtype='float')\n",
    "\n",
    "        for px_dist in range(0, N_Pixel):\n",
    "            shifted_data = quad[:,px_dist+1:].astype(float)\n",
    "            data_section = quad[:,:-px_dist-1].astype(float)\n",
    "            if False:\n",
    "                print(f'shifted data= {shifted_data.shape}')\n",
    "                print(f'sectioned data= {data_section.shape}')\n",
    "            difference = (data_section-shifted_data)**2\n",
    "            product = (data_section*shifted_data)\n",
    "            HHcorr[px_dist] = np.mean(difference)\n",
    "            autocorr[px_dist]= 2*np.mean(product)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (9,5))\n",
    "        ax = np.ravel(ax)\n",
    "        \n",
    "        AFM = ax[0].imshow(quad, cmap = 'inferno', vmax=1.8)\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title(f\"AFM Image\")\n",
    "    #     fig.colorbar(AFM, ax=ax[0])\n",
    "\n",
    "        ax[1].semilogx(Xdelta, autocorr, label = 'Auto-corr', linewidth = 2, alpha=1)\n",
    "                #and its errors:\n",
    "                #plt.errorbar(Xdelta, HHcorr, yerr=e, fmt=\".\")\n",
    "                \n",
    "        fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
